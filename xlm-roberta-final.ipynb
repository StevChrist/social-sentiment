{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e3820f0c1aaf8ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T22:19:04.716307Z",
     "start_time": "2025-09-08T22:18:54.898282Z"
    }
   },
   "outputs": [],
   "source": [
    "# Jika CPU-only: ganti baris torch ‚Üí \"torch==2.3.1\" + index-url CPU.\n",
    "!pip -q install --upgrade pip\n",
    "!pip -q install \"torch==2.3.1+cu121\" --index-url https://download.pytorch.org/whl/cu121\n",
    "!pip -q install \"transformers==4.44.2\" \"accelerate==0.33.0\" \"datasets==2.20.0\" \"evaluate==0.4.1\"\n",
    "!pip -q install \"scikit-learn==1.5.2\" \"pandas==2.2.2\" \"pyarrow==16.1.0\" \"ipykernel\"\n",
    "!pip -q install sentencepiece==0.1.99 \"protobuf>=3.20,<5\" tokenizers>=0.19.0\n",
    "# (opsional) progress bar mulus di notebook\n",
    "!pip -q install ipywidgets==8.1.2 jupyterlab_widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6651008ecb62996",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T22:19:08.656158Z",
     "start_time": "2025-09-08T22:19:04.723664Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: D:\\.Portofolio\\Coding\\social-sentiment\\.venv\\Scripts\\python.exe\n",
      "torch: 2.3.1+cu121 | cuda: 12.1 | is_cuda: True\n",
      "transformers: 4.44.2 | datasets: 2.20.0 | accelerate: 0.33.0\n"
     ]
    }
   ],
   "source": [
    "import sys, torch, transformers, datasets, accelerate\n",
    "print(\"Python:\", sys.executable)\n",
    "print(\"torch:\", torch.__version__, \"| cuda:\", torch.version.cuda, \"| is_cuda:\", torch.cuda.is_available())\n",
    "print(\"transformers:\", transformers.__version__, \"| datasets:\", datasets.__version__, \"| accelerate:\", accelerate.__version__)\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcfffebb453a84db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T22:19:23.449799Z",
     "start_time": "2025-09-08T22:19:08.661042Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['text', 'label'],\n",
       "         num_rows: 45615\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['text', 'label'],\n",
       "         num_rows: 12284\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['text', 'label'],\n",
       "         num_rows: 2000\n",
       "     })\n",
       " }),\n",
       " DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['text', 'label'],\n",
       "         num_rows: 11000\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['text', 'label'],\n",
       "         num_rows: 1260\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['text', 'label'],\n",
       "         num_rows: 500\n",
       "     })\n",
       " }),\n",
       " 'indonlu-smsa')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# EN: TweetEval sentiment (0=neg,1=neu,2=pos)\n",
    "ds_en = load_dataset(\"cardiffnlp/tweet_eval\", \"sentiment\")\n",
    "\n",
    "# ID: IndoNLU SmSA (butuh trust_remote_code) ‚Üí fallback ke NusaX-senti jika gagal\n",
    "try:\n",
    "    ds_id = load_dataset(\"indonlp/indonlu\", \"smsa\", trust_remote_code=True)\n",
    "    src_id = \"indonlu-smsa\"\n",
    "except Exception as e:\n",
    "    print(\"‚ö†Ô∏è IndoNLU SmSA gagal, fallback ke NusaX-senti (id). Error:\", e)\n",
    "    ds_id = load_dataset(\"indonlp/NusaX-senti\", \"id\")\n",
    "    src_id = \"nusax-senti\"\n",
    "\n",
    "ds_en, ds_id, src_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6aac52e455764b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T22:19:24.254241Z",
     "start_time": "2025-09-08T22:19:23.475446Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e4abb37b4f54d118115f2f8395eb2eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e8b4141df8540cc9eec3b5299de98c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1260 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dafe4d9f7624b1cbf89f40b6686734b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'lang'],\n",
       "        num_rows: 56615\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label', 'lang'],\n",
       "        num_rows: 3260\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'lang'],\n",
       "        num_rows: 12784\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "# EN map: label sudah int (0/1/2)\n",
    "def map_en(x):\n",
    "    return {\"text\": x[\"text\"], \"label\": int(x[\"label\"]), \"lang\": \"en\"}\n",
    "en_splits = {k: ds_en[k].map(map_en, remove_columns=ds_en[k].column_names) for k in ds_en.keys()}\n",
    "\n",
    "# ID map: bisa string/ClassLabel ‚Üí jadikan 0/1/2\n",
    "try:\n",
    "    id_label_names = ds_id[\"train\"].features[\"label\"].names\n",
    "except Exception:\n",
    "    id_label_names = None\n",
    "\n",
    "def map_id(x):\n",
    "    mapping = {\"negative\": 0, \"neutral\": 1, \"positive\": 2}\n",
    "    if id_label_names and isinstance(x[\"label\"], int):\n",
    "        name = id_label_names[x[\"label\"]].lower()\n",
    "    else:\n",
    "        name = str(x[\"label\"]).lower()\n",
    "    if name in mapping:\n",
    "        y = mapping[name]\n",
    "    else:\n",
    "        # fallback jika sudah int 0/1/2\n",
    "        y = int(x[\"label\"])\n",
    "    return {\"text\": x[\"text\"], \"label\": y, \"lang\": \"id\"}\n",
    "\n",
    "id_splits = {k: ds_id[k].map(map_id, remove_columns=ds_id[k].column_names) for k in ds_id.keys()}\n",
    "\n",
    "def concat_if_exists(split):\n",
    "    parts = []\n",
    "    if split in en_splits: parts.append(en_splits[split])\n",
    "    if split in id_splits: parts.append(id_splits[split])\n",
    "    return Dataset.from_pandas(pd.concat([p.to_pandas() for p in parts], ignore_index=True))\n",
    "\n",
    "merged = DatasetDict({\n",
    "    \"train\": concat_if_exists(\"train\"),\n",
    "    \"validation\": concat_if_exists(\"validation\"),\n",
    "    \"test\": concat_if_exists(\"test\"),\n",
    "})\n",
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "523731daaa1b74dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T22:19:24.310851Z",
     "start_time": "2025-09-08T22:19:24.270915Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TRAIN === Rows: 56615\n",
      "Lang counts:\n",
      " lang\n",
      "en    45615\n",
      "id    11000\n",
      "Name: count, dtype: int64\n",
      "Label counts (0=neg,1=neu,2=pos):\n",
      " label\n",
      "2    24265\n",
      "1    21821\n",
      "0    10529\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "=== VALIDATION === Rows: 3260\n",
      "Lang counts:\n",
      " lang\n",
      "en    2000\n",
      "id    1260\n",
      "Name: count, dtype: int64\n",
      "Label counts (0=neg,1=neu,2=pos):\n",
      " label\n",
      "2    1554\n",
      "1    1000\n",
      "0     706\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "=== TEST === Rows: 12784\n",
      "Lang counts:\n",
      " lang\n",
      "en    12284\n",
      "id      500\n",
      "Name: count, dtype: int64\n",
      "Label counts (0=neg,1=neu,2=pos):\n",
      " label\n",
      "1    6025\n",
      "0    4176\n",
      "2    2583\n",
      "Name: count, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for split in merged:\n",
    "    df = merged[split].to_pandas()\n",
    "    print(f\"=== {split.upper()} === Rows:\", len(df))\n",
    "    print(\"Lang counts:\\n\", df[\"lang\"].value_counts())\n",
    "    print(\"Label counts (0=neg,1=neu,2=pos):\\n\", df[\"label\"].value_counts(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "323dcc6b447b5f0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T22:19:29.957560Z",
     "start_time": "2025-09-08T22:19:24.382529Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e8d2396ac1543d99524243da2196a85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/56615 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43a152798a924f92b4829ecdcb8cd888",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3260 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "317e863673824fada5aef6d3b0688d1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12784 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying FAST tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\.Portofolio\\Coding\\social-sentiment\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded FAST tokenizer.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from datasets import DatasetDict\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "MODEL_NAME = \"cardiffnlp/twitter-xlm-roberta-base-sentiment\"\n",
    "\n",
    "def clean_text(t: str):\n",
    "    t = re.sub(r\"http\\S+|www\\.\\S+\", \"<URL>\", t)\n",
    "    t = re.sub(r\"@\\w+\", \"<USER>\", t)\n",
    "    return t.strip()\n",
    "\n",
    "def add_clean(batch):\n",
    "    return {\"text\": [clean_text(x) for x in batch[\"text\"]]}\n",
    "\n",
    "merged_clean = DatasetDict({\n",
    "    split: merged[split].map(add_clean, batched=True)\n",
    "    for split in merged.keys()\n",
    "})\n",
    "\n",
    "def load_tokenizer_robust(model_name):\n",
    "    # 1) fast\n",
    "    try:\n",
    "        print(\"Trying FAST tokenizer...\")\n",
    "        tok = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "        print(\"Loaded FAST tokenizer.\")\n",
    "        return tok\n",
    "    except Exception as e1:\n",
    "        print(\"FAST tokenizer failed:\", e1)\n",
    "    # 2) slow\n",
    "    try:\n",
    "        print(\"Trying SLOW tokenizer (SentencePiece)...\", end=\"\")\n",
    "        tok = AutoTokenizer.from_pretrained(model_name, use_fast=False)\n",
    "        print(\"Loaded SLOW tokenizer.\")\n",
    "        return tok\n",
    "    except Exception as e2:\n",
    "        print(\"\\nSLOW tokenizer failed:\", e2)\n",
    "    # 3) fallback\n",
    "    print(\"FALLBACK to 'xlm-roberta-base' tokenizer...\")\n",
    "    tok = AutoTokenizer.from_pretrained(\"xlm-roberta-base\", use_fast=False)\n",
    "    print(\"Loaded fallback tokenizer.\")\n",
    "    return tok\n",
    "\n",
    "tokenizer = load_tokenizer_robust(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fb370011942d1f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T22:19:34.492987Z",
     "start_time": "2025-09-08T22:19:29.964387Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1b4345ff4b5405e80cfe3d70795bfb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/56615 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a964fb77c8f649ce9734dbdc5597ce32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3260 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44615e9649df4f40ac67aed54528e888",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12784 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': ['label', 'input_ids', 'attention_mask'], 'validation': ['label', 'input_ids', 'attention_mask'], 'test': ['label', 'input_ids', 'attention_mask']}\n",
      "{'train': 56615, 'validation': 3260, 'test': 12784}\n"
     ]
    }
   ],
   "source": [
    "from datasets import DatasetDict\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "def tok(batch):\n",
    "    return tokenizer(batch[\"text\"], truncation=True, max_length=160)\n",
    "\n",
    "def build_tokd(ds):\n",
    "    out = {}\n",
    "    for split in ds.keys():\n",
    "        # hanya 'label' dipertahankan; buang 'text','lang' agar collator tidak mencoba mem-pad string\n",
    "        keep = [\"label\"]\n",
    "        remove_cols = [c for c in ds[split].column_names if c not in keep]\n",
    "        out[split] = ds[split].map(tok, batched=True, remove_columns=remove_cols)\n",
    "    return DatasetDict(out)\n",
    "\n",
    "_src = merged_clean  # pakai yang sudah dibersihkan\n",
    "tokd = build_tokd(_src)\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "print({k: tokd[k].column_names for k in tokd})  # ‚Üí ['label','input_ids','attention_mask',(...)]\n",
    "print({k: tokd[k].num_rows for k in tokd})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60a455b28329d89d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T22:19:41.828848Z",
     "start_time": "2025-09-08T22:19:34.502124Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "num_labels = 3\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=num_labels)\n",
    "\n",
    "def metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "    return {\"accuracy\": accuracy_score(labels, preds),\n",
    "            \"macro_f1\": f1_score(labels, preds, average=\"macro\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "608ff0e70359d9ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T22:19:46.233497Z",
     "start_time": "2025-09-08T22:19:41.837167Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\.Portofolio\\Coding\\social-sentiment\\.venv\\Lib\\site-packages\\transformers\\training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import TrainingArguments, Trainer, EarlyStoppingCallback\n",
    "from torch.utils.data import WeightedRandomSampler, DataLoader\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"artifacts/xlmr-sentiment\",\n",
    "    learning_rate=1e-5,                 # kecil karena mulai dari checkpoint tugas-spesifik\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=5,                  # early stop menjaga overfit\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"macro_f1\",\n",
    "    greater_is_better=True,\n",
    "    warmup_ratio=0.1,\n",
    "    logging_steps=100,\n",
    "    seed=42,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    label_smoothing_factor=0.05\n",
    ")\n",
    "\n",
    "# bobot dari distribusi label + bahasa (di dataset sebelum dibuang kolom)\n",
    "train_df = _src[\"train\"].to_pandas()\n",
    "label_counts = train_df[\"label\"].value_counts().to_dict()\n",
    "lang_counts  = train_df[\"lang\"].value_counts().to_dict()\n",
    "\n",
    "weights = []\n",
    "for _, r in train_df.iterrows():\n",
    "    wl = 1.0 / label_counts[r[\"label\"]]\n",
    "    wg = 1.0 / lang_counts[r[\"lang\"]]\n",
    "    weights.append(wl * wg)\n",
    "\n",
    "weights = torch.DoubleTensor(weights)\n",
    "sampler = WeightedRandomSampler(weights, num_samples=len(weights), replacement=True)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    tokd[\"train\"],\n",
    "    batch_size=args.per_device_train_batch_size,\n",
    "    sampler=sampler,\n",
    "    collate_fn=data_collator\n",
    ")\n",
    "\n",
    "class SamplerTrainer(Trainer):\n",
    "    def get_train_dataloader(self):\n",
    "        return train_loader\n",
    "\n",
    "trainer = SamplerTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokd[\"train\"],\n",
    "    eval_dataset=tokd[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f21bba7b655d767d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T04:30:00.030190Z",
     "start_time": "2025-09-08T22:19:46.242834Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17695' max='17695' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17695/17695 6:09:47, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.446200</td>\n",
       "      <td>0.514444</td>\n",
       "      <td>0.829448</td>\n",
       "      <td>0.816721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.378100</td>\n",
       "      <td>0.546475</td>\n",
       "      <td>0.824540</td>\n",
       "      <td>0.812002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.372100</td>\n",
       "      <td>0.555685</td>\n",
       "      <td>0.832209</td>\n",
       "      <td>0.821462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.343300</td>\n",
       "      <td>0.561373</td>\n",
       "      <td>0.833129</td>\n",
       "      <td>0.822511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.317000</td>\n",
       "      <td>0.580424</td>\n",
       "      <td>0.833129</td>\n",
       "      <td>0.821009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='502' max='102' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [102/102 00:17]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val (balanced): {'eval_loss': 0.5613728761672974, 'eval_accuracy': 0.8331288343558282, 'eval_macro_f1': 0.8225106053485268, 'eval_runtime': 4.4935, 'eval_samples_per_second': 725.491, 'eval_steps_per_second': 22.699, 'epoch': 5.0}\n",
      "Test (balanced): {'eval_loss': 0.8344465494155884, 'eval_accuracy': 0.7103410513141427, 'eval_macro_f1': 0.7130114351314533, 'eval_runtime': 13.4281, 'eval_samples_per_second': 952.033, 'eval_steps_per_second': 29.788, 'epoch': 5.0}\n",
      "Saved to: artifacts/xlmr-sentiment-best-balanced\n"
     ]
    }
   ],
   "source": [
    "train_result = trainer.train()\n",
    "\n",
    "val_metrics = trainer.evaluate(tokd[\"validation\"])\n",
    "test_metrics = trainer.evaluate(tokd[\"test\"])\n",
    "print(\"Val (balanced):\", val_metrics)\n",
    "print(\"Test (balanced):\", test_metrics)\n",
    "\n",
    "save_dir = \"artifacts/xlmr-sentiment-best-balanced\"\n",
    "trainer.save_model(save_dir)\n",
    "tokenizer.save_pretrained(save_dir)\n",
    "print(\"Saved to:\", save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7959bce19d1b3e9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T04:30:16.455976Z",
     "start_time": "2025-09-09T04:30:00.101446Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== VALIDATION per language ===\n",
      "Lang=en  n=2000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg     0.6676    0.7596    0.7106       312\n",
      "         neu     0.7631    0.7043    0.7325       869\n",
      "         pos     0.8066    0.8303    0.8183       819\n",
      "\n",
      "    accuracy                         0.7645      2000\n",
      "   macro avg     0.7458    0.7647    0.7538      2000\n",
      "weighted avg     0.7660    0.7645    0.7642      2000\n",
      "\n",
      "Lang=id  n=1260\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg     0.9233    0.9467    0.9348       394\n",
      "         neu     0.8952    0.8473    0.8706       131\n",
      "         pos     0.9604    0.9565    0.9584       735\n",
      "\n",
      "    accuracy                         0.9421      1260\n",
      "   macro avg     0.9263    0.9168    0.9213      1260\n",
      "weighted avg     0.9420    0.9421    0.9419      1260\n",
      "\n",
      "=== TEST per language ===\n",
      "Lang=en  n=12284\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg     0.6812    0.7842    0.7291      3972\n",
      "         neu     0.7444    0.6293    0.6820      5937\n",
      "         pos     0.6545    0.7419    0.6955      2375\n",
      "\n",
      "    accuracy                         0.7012     12284\n",
      "   macro avg     0.6934    0.7185    0.7022     12284\n",
      "weighted avg     0.7066    0.7012    0.6998     12284\n",
      "\n",
      "Lang=id  n=500\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg     0.9309    0.9902    0.9596       204\n",
      "         neu     0.9565    0.7500    0.8408        88\n",
      "         pos     0.9346    0.9615    0.9479       208\n",
      "\n",
      "    accuracy                         0.9360       500\n",
      "   macro avg     0.9407    0.9006    0.9161       500\n",
      "weighted avg     0.9369    0.9360    0.9338       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, torch\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def eval_subset(dataset, lang_code, batch_size=32, max_len=128, use_fp16=True):\n",
    "    df = dataset.to_pandas()\n",
    "    sub = df[df[\"lang\"] == lang_code]\n",
    "    if len(sub) == 0:\n",
    "        print(f\"No samples for lang={lang_code}\")\n",
    "        return\n",
    "    texts = sub[\"text\"].tolist()\n",
    "    y_true = sub[\"label\"].to_numpy()\n",
    "    preds_all = []\n",
    "\n",
    "    device = model.device\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            enc = tokenizer(texts[i:i+batch_size], truncation=True, max_length=max_len, padding=True, return_tensors=\"pt\").to(device)\n",
    "            if use_fp16 and torch.cuda.is_available():\n",
    "                with torch.cuda.amp.autocast(dtype=torch.float16):\n",
    "                    logits = model(**enc).logits\n",
    "            else:\n",
    "                logits = model(**enc).logits\n",
    "            preds = logits.argmax(dim=1).detach().cpu().numpy()\n",
    "            preds_all.append(preds)\n",
    "            del enc, logits\n",
    "            if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
    "\n",
    "    y_pred = np.concatenate(preds_all, axis=0)\n",
    "    print(f\"Lang={lang_code}  n={len(texts)}\")\n",
    "    print(classification_report(y_true, y_pred, digits=4, target_names=[\"neg\",\"neu\",\"pos\"]))\n",
    "\n",
    "ds_val  = merged_clean[\"validation\"]\n",
    "ds_test = merged_clean[\"test\"]\n",
    "\n",
    "print(\"=== VALIDATION per language ===\")\n",
    "eval_subset(ds_val, \"en\", batch_size=32, max_len=128, use_fp16=True)\n",
    "eval_subset(ds_val, \"id\", batch_size=32, max_len=128, use_fp16=True)\n",
    "\n",
    "print(\"=== TEST per language ===\")\n",
    "eval_subset(ds_test, \"en\", batch_size=32, max_len=128, use_fp16=True)\n",
    "eval_subset(ds_test, \"id\", batch_size=32, max_len=128, use_fp16=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1bd3caaab6c53518",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T04:30:31.780157Z",
     "start_time": "2025-09-09T04:30:16.469208Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best t_neu on VAL = 0.34 | macro-F1 = 0.8286\n",
      "TEST (thresholded) macro-F1: 0.7208214535440476\n",
      "TEST (thresholded) accuracy: 0.7193366708385481\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg     0.7130    0.7646    0.7379      4176\n",
      "         neu     0.7308    0.6825    0.7058      6025\n",
      "         pos     0.7059    0.7321    0.7187      2583\n",
      "\n",
      "    accuracy                         0.7193     12784\n",
      "   macro avg     0.7166    0.7264    0.7208     12784\n",
      "weighted avg     0.7199    0.7193    0.7189     12784\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, torch\n",
    "from sklearn.metrics import f1_score, classification_report, accuracy_score\n",
    "\n",
    "runner = trainer\n",
    "model_eval = runner.model\n",
    "bs = 32\n",
    "\n",
    "# --- VAL probs ---\n",
    "val_texts = ds_val[\"text\"]; val_labels = np.array(ds_val[\"label\"])\n",
    "probs = []\n",
    "model_eval.eval()\n",
    "with torch.no_grad():\n",
    "    for i in range(0, len(val_texts), bs):\n",
    "        enc = tokenizer(val_texts[i:i+bs], truncation=True, max_length=160, padding=True, return_tensors=\"pt\").to(model_eval.device)\n",
    "        lg  = model_eval(**enc).logits.detach().cpu().numpy()\n",
    "        ex  = np.exp(lg - lg.max(axis=1, keepdims=True))\n",
    "        probs.append(ex / ex.sum(axis=1, keepdims=True))\n",
    "        if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
    "probs_val = np.vstack(probs)\n",
    "\n",
    "def predict_with_t_neu(ps, t):\n",
    "    pred = np.argmax(ps, axis=1).copy()\n",
    "    pred[ps[:,1] >= t] = 1\n",
    "    return pred\n",
    "\n",
    "best_t, best_f1 = 0.5, -1\n",
    "for t in np.linspace(0.30, 0.70, 21):\n",
    "    f1m = f1_score(val_labels, predict_with_t_neu(probs_val, t), average=\"macro\")\n",
    "    if f1m > best_f1:\n",
    "        best_f1, best_t = f1m, t\n",
    "print(f\"Best t_neu on VAL = {best_t:.2f} | macro-F1 = {best_f1:.4f}\")\n",
    "\n",
    "# --- TEST apply ---\n",
    "test_texts = ds_test[\"text\"]; test_labels = np.array(ds_test[\"label\"])\n",
    "probs = []\n",
    "with torch.no_grad():\n",
    "    for i in range(0, len(test_texts), bs):\n",
    "        enc = tokenizer(test_texts[i:i+bs], truncation=True, max_length=160, padding=True, return_tensors=\"pt\").to(model_eval.device)\n",
    "        lg  = model_eval(**enc).logits.detach().cpu().numpy()\n",
    "        ex  = np.exp(lg - lg.max(axis=1, keepdims=True))\n",
    "        probs.append(ex / ex.sum(axis=1, keepdims=True))\n",
    "        if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
    "probs_test = np.vstack(probs)\n",
    "\n",
    "pred_test = predict_with_t_neu(probs_test, best_t)\n",
    "print(\"TEST (thresholded) macro-F1:\", f1_score(test_labels, pred_test, average=\"macro\"))\n",
    "print(\"TEST (thresholded) accuracy:\", accuracy_score(test_labels, pred_test))\n",
    "print(classification_report(test_labels, pred_test, digits=4, target_names=[\"neg\",\"neu\",\"pos\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eedd9ea7e8c5bff9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T04:30:34.954485Z",
     "start_time": "2025-09-09T04:30:31.785907Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: artifacts/xlmr-sentiment-best-balanced | t_neu = 0.33999999999999997\n"
     ]
    }
   ],
   "source": [
    "import os, json\n",
    "best_dir = \"artifacts/xlmr-sentiment-best-balanced\"\n",
    "trainer.save_model(best_dir)\n",
    "tokenizer.save_pretrained(best_dir)\n",
    "with open(os.path.join(best_dir, \"inference_config.json\"), \"w\") as f:\n",
    "    json.dump({\"t_neu\": float(best_t)}, f, indent=2)\n",
    "print(\"Saved to:\", best_dir, \"| t_neu =\", best_t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
